#!/usr/bin/env python3
"""
Embedding Utilities - Text to Vector Conversion
Sentence-transformers kullanarak TÃ¼rkÃ§e metinler iÃ§in embedding oluÅŸturur
"""

import os
from typing import List, Optional
import hashlib

try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    SentenceTransformer = None

# Global model instance (lazy loading)
_embedding_model = None
_embedding_model_name = "paraphrase-multilingual-MiniLM-L12-v2"  # TÃ¼rkÃ§e destekleyen model


def get_embedding_model():
    """Embedding model'ini yÃ¼kle (singleton)"""
    global _embedding_model
    
    if SentenceTransformer is None:
        raise ImportError(
            "sentence-transformers yÃ¼klÃ¼ deÄŸil. YÃ¼klemek iÃ§in: pip install sentence-transformers"
        )
    
    if _embedding_model is None:
        print(f"ğŸ”„ Embedding model yÃ¼kleniyor: {_embedding_model_name}")
        _embedding_model = SentenceTransformer(_embedding_model_name)
        print(f"âœ“ Model yÃ¼klendi (embedding size: {_embedding_model.get_sentence_embedding_dimension()})")
    
    return _embedding_model


def generate_embedding(text: str) -> List[float]:
    """
    Metni embedding vector'Ã¼ne dÃ¶nÃ¼ÅŸtÃ¼r
    
    Args:
        text: Embedding oluÅŸturulacak metin
        
    Returns:
        Embedding vector (List[float])
    """
    model = get_embedding_model()
    embedding = model.encode(text, convert_to_numpy=True, normalize_embeddings=True)
    return embedding.tolist()


def generate_embeddings(texts: List[str], batch_size: int = 32) -> List[List[float]]:
    """
    Birden fazla metni batch olarak embedding vector'Ã¼ne dÃ¶nÃ¼ÅŸtÃ¼r
    
    Args:
        texts: Embedding oluÅŸturulacak metin listesi
        batch_size: Batch size for processing
        
    Returns:
        Embedding vector listesi
    """
    model = get_embedding_model()
    embeddings = model.encode(
        texts, 
        convert_to_numpy=True, 
        normalize_embeddings=True,
        batch_size=batch_size,
        show_progress_bar=len(texts) > 10
    )
    return embeddings.tolist()


def get_embedding_dimension() -> int:
    """Embedding dimension'Ä±nÄ± dÃ¶ndÃ¼r"""
    model = get_embedding_model()
    return model.get_sentence_embedding_dimension()


def generate_vector_id(text: str, prefix: str = "") -> str:
    """
    Metinden unique vector ID oluÅŸtur
    
    Args:
        text: ID oluÅŸturulacak metin
        prefix: ID'ye eklenecek prefix (Ã¶rn: tenant slug)
        
    Returns:
        Unique vector ID (hash-based)
    """
    content = f"{prefix}_{text}" if prefix else text
    vector_id = hashlib.md5(content.encode('utf-8')).hexdigest()
    return vector_id


# Test
if __name__ == "__main__":
    print("ğŸ§ª Embedding utility testi...")
    
    try:
        # Test embedding generation
        test_text = "AkÃ§ansa'nÄ±n Åubat 2025 ve Nisan 2025 arasÄ±ndaki hava kalitesi analizi"
        embedding = generate_embedding(test_text)
        print(f"âœ“ Embedding oluÅŸturuldu: {len(embedding)} boyutlu")
        print(f"âœ“ Ä°lk 5 deÄŸer: {embedding[:5]}")
        
        # Test batch embedding
        test_texts = [
            "PM10 deÄŸerleri Åubat ayÄ±nda yÃ¼ksekti",
            "PM2.5 deÄŸerleri Nisan ayÄ±nda dÃ¼ÅŸÃ¼ktÃ¼",
            "NO2 seviyeleri karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±"
        ]
        embeddings = generate_embeddings(test_texts)
        print(f"âœ“ Batch embedding oluÅŸturuldu: {len(embeddings)} adet")
        
        # Test dimension
        dim = get_embedding_dimension()
        print(f"âœ“ Embedding dimension: {dim}")
        
        # Test vector ID generation
        vector_id = generate_vector_id(test_text, prefix="akcansa")
        print(f"âœ“ Vector ID oluÅŸturuldu: {vector_id}")
        
    except ImportError as e:
        print(f"âŒ Hata: {e}")
        print("\nÃ‡Ã¶zÃ¼m:")
        print("  pip install sentence-transformers")
